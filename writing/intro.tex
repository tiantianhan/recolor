%introduction
The modern beauty, cosmetics and apparel shopping experiences increasingly take place online and digitally, enhanced by \textit{virtual try-on} applications which demonstrate products on digital models to provide previews and vicarious experiences of the products for the users \cite{zhang_2017_try}. Increasingly these applications can either use images of the user themselves to demonstrate products or digitally modify the models to take on the user's physical characteristics such as skin colour, facial features and body measurements \cite{shilkrot_2013_garment, li_2015_replace}. A study by Merle et al. shows that this increasing ``perceived resemblance" between the user and the model increases the user's sense of connection to the model and is an important factor in increasing the user's perceived usefulness of the application and the positive user responses to the demonstrated products \cite{merle_2012_tryon}.

% The physical differences between ourselves and a model means that we often cannot judge based on the appearance of a product worn by a model how that product will actually look on ourselves. Ideally, to help us, the users, make better informed purchasing decisions, the model demonstrating the product should be customized to each user. To achieve this, there are already many applications developed for virtually trying on products in the beauty, cosmetics and garment industries which digitally modify the images of models to take on the appearance of the user \cite{zhang_2017_try} \cite{shilkrot_2013_garment, li_2015_replace}.
%better describe "virtual try-on?"

Our project is concerned with improving the perceived user-model resemblence for a particular virtual try-on mobile application, which currently demonstrates different nail polish colours on a video of a generic model hand. We would like instead to have the skin colour of the model hand be matched to each user's skin colour, so that the contrast between the nail polish colours and the user's skin can be clearly visualized. However, because preparing even a single video for virtual try-on is an extremely time intensive task, it is not feasible to manually prepare a large number of different demo videos with models of a range skin colours that would satisfy all users.

To address this challenge, we will develop an algorithm to incorporate into the application so that for each user using an instance of the application, the algorithm would quickly and automatically edit each frame of the video of the generic model hand so that the skin colour of the user is transfered to the image of the model hand. The user should only need to provide an image of their own hand as input, and a wide range of user skin colours should be supported by a single base video of a model of mid-toned skin colour. The process should be also able to run quickly on a mobile device, such that the user notices no significant time lag to see the resulting video upon inputting their own skin colour. We will discuss the requirements for our project in detail in Section \ref{sec:goals}.

%todo better describe colour transfer??
Currently, we aren't aware of an existing algorithm for skin colour transfer that satisfies all our specific requirements. While there has been a large body of work done addressing transfer of colour between images in general \cite{reinhard_2001_transfer, pitie_2005_pdf, chen_2014_propagation, chang_2015_palette, zhang_2017_decomposition}, only a smaller subset of the work addresses skin colour specifically\cite{yin_2004_transfer, seo_2005_transfer, yang_2017_semantic}. All such studies address images of facial portraits rather than hands, which often means that the bulk of the study is dedicated to solutions for the colour transfer of the various complex features of the face \cite{yang_2017_semantic}. Simple skin colour transfer is also used as a part of certain other imaging processing applications, but similarly, since the skin colour transfer is often only a small part of the whole project, the algorithms used are often relatively simple and not heavily designed for achieving accuracy to the user skin colour \cite{shilkrot_2013_garment, li_2015_replace}. In the related field of skin colour enhancement applications, the methods used are generally meant for small skin colour adjustments and not for making large changes to the user skin colour \cite{aradhye_2009_enhancement, lee_2010_mobile}. Finally, algorithms developed by most of the prior studies do not appear to be meant for use with the limited resources on a mobile device. We will discuss these previous studies of methods of skin colour transfer in detail in the following section, Section \ref{sec:academic_work}.

% Our goal is to develop a mobile compatible recolouring algorithm that would satisfy our requirements. As sub-objectives, we would like to first develop an effective algorithm and then optimize the algorithm's running time. We will focus solely on achieving convincing colour transfer in the algorithm, and assume that the location of the skin in the images are already determined by an another process. 

% For developing and testing the algorithm, we will be using the OpenCV library in C++. OpenCV has a wide range of image processing tools and code in C++ should be easy to optimize and port to mobile platforms. We will develop the algorithm on a desktop computer, to allow for faster and easier testing, before we port the code to mobile. Our approach will be to test different algorithms on variety of hand images, starting with a naive approach and developing improved versions of the algorithm based on the results after each each iteration.